{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95c5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff098b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, data paths are hardcoded\n",
    "\n",
    "submissions_data_path = r\"C:\\Users\\marti\\OneDrive\\Bureaublad\\Minor AI\\NLP\\Project\\bigdata\\amitheasshole\\amitheasshole_submissions.ndjson\"\n",
    "comments_data_path = r\"C:\\Users\\marti\\OneDrive\\Bureaublad\\Minor AI\\NLP\\Project\\bigdata\\amitheasshole\\amitheasshole_comments.ndjson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021a006",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dict contains fields not in fieldnames: 'link_flair_template_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m             writer = csv.DictWriter(csv_file, fieldnames=record.keys())\n\u001b[32m     16\u001b[39m             writer.writeheader()\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m         \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwriterow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Conversion complete! File saved as:\u001b[39m\u001b[33m\"\u001b[39m, output_file)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.13.7-windows-x86_64-none\\Lib\\csv.py:226\u001b[39m, in \u001b[36mDictWriter.writerow\u001b[39m\u001b[34m(self, rowdict)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwriterow\u001b[39m(\u001b[38;5;28mself\u001b[39m, rowdict):\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.writer.writerow(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dict_to_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrowdict\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.13.7-windows-x86_64-none\\Lib\\csv.py:221\u001b[39m, in \u001b[36mDictWriter._dict_to_list\u001b[39m\u001b[34m(self, rowdict)\u001b[39m\n\u001b[32m    219\u001b[39m     wrong_fields = rowdict.keys() - \u001b[38;5;28mself\u001b[39m.fieldnames\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wrong_fields:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdict contains fields not in fieldnames: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    222\u001b[39m                          + \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28mrepr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m wrong_fields]))\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (rowdict.get(key, \u001b[38;5;28mself\u001b[39m.restval) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fieldnames)\n",
      "\u001b[31mValueError\u001b[39m: dict contains fields not in fieldnames: 'link_flair_template_id'"
     ]
    }
   ],
   "source": [
    "# Input and output file names\n",
    "input_file = submissions_data_path\n",
    "output_file = r\"C:\\Users\\marti\\OneDrive\\Bureaublad\\submissions.csv\"\n",
    "\n",
    "# Step 1: Collect all keys\n",
    "all_keys = set()\n",
    "records = []\n",
    "\n",
    "with open(submissions_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        record = json.loads(line)\n",
    "        records.append(record)\n",
    "        all_keys.update(record.keys())\n",
    "\n",
    "# Step 2: Write to CSV with all possible keys\n",
    "with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=sorted(all_keys))\n",
    "    writer.writeheader()\n",
    "    for record in records:\n",
    "        writer.writerow(record)\n",
    "\n",
    "print(\"✅ Conversion complete! File saved as:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf0c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndjson_to_dataframe(file_path, num_lines):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= num_lines:\n",
    "                break\n",
    "            data.append(json.loads(line))\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53bb051",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_dataframe = ndjson_to_dataframe(submissions_data_path, 1e4)\n",
    "comments_dataframe = ndjson_to_dataframe(comments_data_path, 1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660b4713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['all_awardings', 'archived', 'associated_award', 'author',\n",
      "       'author_created_utc', 'author_flair_background_color',\n",
      "       'author_flair_css_class', 'author_flair_richtext',\n",
      "       'author_flair_template_id', 'author_flair_text',\n",
      "       'author_flair_text_color', 'author_flair_type', 'author_fullname',\n",
      "       'author_patreon_flair', 'author_premium', 'body', 'can_gild',\n",
      "       'collapsed', 'collapsed_because_crowd_control', 'collapsed_reason',\n",
      "       'collapsed_reason_code', 'comment_type', 'controversiality',\n",
      "       'created_utc', 'distinguished', 'edited', 'gilded', 'gildings', 'id',\n",
      "       'is_submitter', 'link_id', 'locked', 'name', 'no_follow', 'parent_id',\n",
      "       'permalink', 'retrieved_on', 'score', 'score_hidden', 'send_replies',\n",
      "       'stickied', 'subreddit', 'subreddit_id', 'subreddit_name_prefixed',\n",
      "       'subreddit_type', 'top_awarded_type', 'total_awards_received',\n",
      "       'treatment_tags', 'unrepliable_reason', 'author_cakeday'],\n",
      "      dtype='object')\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(comments_dataframe.columns)\n",
    "print(len(comments_dataframe.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52ed3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['all_awardings', 'allow_live_comments', 'archived', 'author',\n",
      "       'author_created_utc', 'author_flair_background_color',\n",
      "       'author_flair_css_class', 'author_flair_richtext',\n",
      "       'author_flair_template_id', 'author_flair_text',\n",
      "       'author_flair_text_color', 'author_flair_type', 'author_fullname',\n",
      "       'author_patreon_flair', 'author_premium', 'awarders', 'banned_by',\n",
      "       'can_gild', 'can_mod_post', 'category', 'content_categories',\n",
      "       'contest_mode', 'created_utc', 'discussion_type', 'distinguished',\n",
      "       'domain', 'edited', 'gilded', 'gildings', 'hidden', 'hide_score', 'id',\n",
      "       'is_created_from_ads_ui', 'is_crosspostable', 'is_meta',\n",
      "       'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable',\n",
      "       'is_self', 'is_video', 'link_flair_background_color',\n",
      "       'link_flair_css_class', 'link_flair_richtext', 'link_flair_text',\n",
      "       'link_flair_text_color', 'link_flair_type', 'locked', 'media',\n",
      "       'media_embed', 'media_only', 'name', 'no_follow', 'num_comments',\n",
      "       'num_crossposts', 'over_18', 'parent_whitelist_status', 'permalink',\n",
      "       'pinned', 'pwls', 'quarantine', 'removed_by', 'removed_by_category',\n",
      "       'retrieved_on', 'retrieved_utc', 'score', 'secure_media',\n",
      "       'secure_media_embed', 'selftext', 'send_replies', 'spoiler', 'stickied',\n",
      "       'subreddit', 'subreddit_id', 'subreddit_name_prefixed',\n",
      "       'subreddit_subscribers', 'subreddit_type', 'suggested_sort',\n",
      "       'thumbnail', 'thumbnail_height', 'thumbnail_width', 'title',\n",
      "       'top_awarded_type', 'total_awards_received', 'treatment_tags',\n",
      "       'upvote_ratio', 'url', 'view_count', 'whitelist_status', 'wls',\n",
      "       'link_flair_template_id', 'call_to_action', 'author_cakeday',\n",
      "       'post_hint', 'preview'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(submissions_dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "602a0c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction = 0.2432\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for text in submissions_dataframe['selftext']:\n",
    "    if text != \"[removed]\" and text != \"[deleted]\":\n",
    "        counter += 1\n",
    "\n",
    "print(f\"fraction = {counter/len(submissions_dataframe[\"selftext\"])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58a9ef50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [removed]\n",
       "1       [removed]\n",
       "2       [deleted]\n",
       "3       [removed]\n",
       "4       [removed]\n",
       "          ...    \n",
       "9995    [removed]\n",
       "9996    [removed]\n",
       "9997    [removed]\n",
       "9998    [removed]\n",
       "9999    [removed]\n",
       "Name: selftext, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions_dataframe['selftext']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ti3160tu-nlp-group-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
