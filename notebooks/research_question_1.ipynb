{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c1571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import src.settings as settings\n",
    "from typing import Optional\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7292c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMENTS_NDJSON = settings.DATA_DIR / 'amitheasshole_comments.ndjson'\n",
    "COMMENTS_PARQUET = settings.DATA_DIR / 'amitheasshole_comments.parquet'\n",
    "SUBMISSIONS_NDJSON = settings.DATA_DIR / 'amitheasshole_submissions.ndjson'\n",
    "SUBMISSIONS_PARQUET = settings.DATA_DIR / 'amitheasshole_submissions.parquet'\n",
    "\n",
    "class Flairs(Enum):\n",
    "    YTA = 'Asshole'\n",
    "    NTA = 'Not the A-hole'\n",
    "    ESH = 'Everyone Sucks'\n",
    "    NAH = 'No A-holes here'\n",
    "\n",
    "SHOULD_PRINT_INFO = False\n",
    "SHOULD_PRINT_HEAD = False\n",
    "N_HEAD = 10\n",
    "USE_TOP_LEVEL_COMMENTS_ONLY = True\n",
    "N_BIGGEST_SUBMISSIONS: Optional[int] = 2\n",
    "SHOULD_MAP_OTHER_FLAIRS = True # Map YTA_LIKE to YTA and NTA_LIKE to NTA\n",
    "YTA_LIKE = ('YTA', 'YWBTA', 'ESH')\n",
    "NTA_LIKE = ('NTA', 'YWNBTA', 'NAH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0d965",
   "metadata": {},
   "source": [
    "# (Convert to) and load from parquet into lazy frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUBMISSIONS_PARQUET.exists():\n",
    "    submissions_lf = pl.scan_parquet(SUBMISSIONS_PARQUET)\n",
    "else:\n",
    "    submissions_lf = (\n",
    "        pl.scan_ndjson(\n",
    "            SUBMISSIONS_NDJSON,\n",
    "            schema_overrides={\n",
    "                'edited': pl.Utf8,\n",
    "            },\n",
    "        )\n",
    "        # TODO:\n",
    "        .with_columns(\n",
    "            # TODO:\n",
    "            pl.when(pl.col('edited').is_null() | (pl.col('edited') == 'false'))\n",
    "            .then(False)\n",
    "            .otherwise(True)\n",
    "            .alias('edited')\n",
    "        )\n",
    "        .select([\n",
    "            'author',\n",
    "            'edited',\n",
    "            'link_flair_text',\n",
    "            'name',\n",
    "            'num_comments',\n",
    "            'over_18',\n",
    "            'score',\n",
    "            'selftext',\n",
    "            'title',\n",
    "            'upvote_ratio',\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    submissions_lf.sink_parquet(SUBMISSIONS_PARQUET, engine='streaming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMENTS_PARQUET.exists():\n",
    "    comments_lf = pl.scan_parquet(COMMENTS_PARQUET)\n",
    "else:\n",
    "    comments_lf = (\n",
    "        pl.scan_ndjson(\n",
    "            COMMENTS_NDJSON,\n",
    "            schema_overrides={\n",
    "                'edited': pl.Utf8,\n",
    "            },\n",
    "        )\n",
    "        # TODO:\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('edited').is_null() | (pl.col('edited') == 'false'))\n",
    "            .then(False)\n",
    "            .otherwise(True)\n",
    "            .alias('edited')\n",
    "        )\n",
    "        .select([\n",
    "            'author',\n",
    "            'body',\n",
    "            'edited',\n",
    "            'is_submitter',\n",
    "            'link_id',\n",
    "            'parent_id',\n",
    "            'score',\n",
    "        ]) # TODO: controversiality?\n",
    "    )\n",
    "\n",
    "    comments_lf.sink_parquet(COMMENTS_PARQUET, engine='streaming')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e16de",
   "metadata": {},
   "source": [
    "# Submissions filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f90b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: extract these values to global constant?\n",
    "filtered_submissions_lf = submissions_lf.filter(\n",
    "    pl.col('over_18').is_not_null()\n",
    "    & ~pl.col('over_18')\n",
    "    & pl.col('selftext').is_not_null()\n",
    "    & ~pl.col('selftext').is_in(('[deleted]', '[removed]'))\n",
    "    & pl.col('author').is_not_null()\n",
    "    & ~pl.col('author').is_in(('Judgement_Bot_AITA', 'AutoModerator')) # TODO: often, deleted authors still have post up and not deleted, so don't filter on [deleted]?\n",
    "    & pl.col('link_flair_text').is_in((Flairs.NTA.value, Flairs.YTA.value))\n",
    "    & pl.col('edited').is_not_null()\n",
    "    & ~pl.col('edited') # TODO: perhaps too aggresive, you might lose interesting posts\n",
    "    & pl.all_horizontal(\n",
    "        pl.col('num_comments', 'score', 'title', 'upvote_ratio').is_not_null(),\n",
    "    )\n",
    ")\n",
    "\n",
    "if SHOULD_PRINT_INFO:\n",
    "    print(f'row count submissions original: {submissions_lf.select(pl.len()).collect(engine='streaming').item()}')\n",
    "    print(f'row count submissions filtered: {filtered_submissions_lf.select(pl.len()).collect(engine='streaming').item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f01697",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_submissions_lf = filtered_submissions_lf.sort(pl.col('num_comments'), descending=True) \n",
    "selected_submissions_lf = filtered_submissions_lf if N_BIGGEST_SUBMISSIONS is None else sorted_submissions_lf.limit(N_BIGGEST_SUBMISSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_PRINT_HEAD:\n",
    "    _ = display(selected_submissions_lf.collect(engine='streaming').head(N_HEAD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12931768",
   "metadata": {},
   "source": [
    "# Comments filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: extract these values to global constant?\n",
    "# TODO: null checks\n",
    "filtered_comments_lf = comments_lf.filter(\n",
    "    ~pl.col('body').is_in(('[deleted]', '[removed]'))\n",
    "    & ~pl.col('author').is_in(('Judgement_Bot_AITA', 'AutoModerator')) # TODO: is this the same case as for submissions?\n",
    "    & ~pl.col('edited') # TODO: perhaps too aggresive, you might lose interesting posts\n",
    "    & ~pl.col('is_submitter')\n",
    ")\n",
    "\n",
    "if USE_TOP_LEVEL_COMMENTS_ONLY:\n",
    "    filtered_comments_lf = filtered_comments_lf.filter(\n",
    "        pl.col('parent_id').str.starts_with('t3_') # Comments always start with t1_, submissions with t3_, and subreddits with t5_ #TODO: dit klopt toch?\n",
    "    )\n",
    "\n",
    "if SHOULD_PRINT_INFO:\n",
    "    print(f'row count comments original: {comments_lf.select(pl.len()).collect(engine='streaming').item()}')\n",
    "    print(f'row count comments filtered: {filtered_comments_lf.select(pl.len()).collect(engine='streaming').item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92653b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: necessary if we take all submissions?\n",
    "matched_comments_lf = filtered_comments_lf.join(\n",
    "    selected_submissions_lf,\n",
    "    left_on='parent_id',\n",
    "    right_on='name',\n",
    "    how='semi',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6adb090",
   "metadata": {},
   "source": [
    "# Calculate submission features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: debug\n",
    "matched_comments_lf = matched_comments_lf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aaaa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_features_lf = (\n",
    "    selected_submissions_lf\n",
    "    .with_columns(\n",
    "        ground_truth_majority_vote=(\n",
    "            pl.when(pl.col('link_flair_text') == 'Asshole').then(pl.lit('YTA'))\n",
    "            .when(pl.col('link_flair_text') == Flairs.ESH.value).then(pl.lit('ESH'))\n",
    "            .when(pl.col('link_flair_text') == Flairs.NTA.value).then(pl.lit('NTA'))\n",
    "            .when(pl.col('link_flair_text') == Flairs.NAH.value).then(pl.lit('NAH'))\n",
    "            .otherwise(None)\n",
    "        ),\n",
    "        text_length=(\n",
    "            pl.col('title').str.len_chars()\n",
    "            + pl.col('selftext').str.len_chars()\n",
    "        ),\n",
    "    )\n",
    "    .filter(pl.col('ground_truth_majority_vote').is_not_null())\n",
    "    .select(\n",
    "        'name',\n",
    "        'ground_truth_majority_vote',\n",
    "        'text_length',\n",
    "        'link_flair_text', # TODO: DEBUG\n",
    "        'score',\n",
    "        'upvote_ratio',\n",
    "    )\n",
    ")\n",
    "\n",
    "if SHOULD_MAP_OTHER_FLAIRS:\n",
    "    submission_features_lf = (\n",
    "        submission_features_lf\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('ground_truth_majority_vote') == 'ESH').then(pl.lit('YTA'))\n",
    "            .when(pl.col('ground_truth_majority_vote') == 'NAH').then(pl.lit('NTA'))\n",
    "            .otherwise(pl.col('ground_truth_majority_vote'))\n",
    "            .alias('ground_truth_majority_vote')\n",
    "        )\n",
    "    )\n",
    "\n",
    "if SHOULD_PRINT_HEAD:\n",
    "    _ = display(submission_features_lf.collect(engine='streaming').head(N_HEAD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e91aa2",
   "metadata": {},
   "source": [
    "# Extract vote from each comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4edd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_lowercase = pl.col('body').str.to_lowercase()\n",
    "comment_votes_lf = (\n",
    "    matched_comments_lf\n",
    "    .filter(~pl.col('body').str.contains(r'\\bINFO\\b', literal=True))\n",
    "    .with_columns(\n",
    "        extracted_vote=(\n",
    "            pl.when(body_lowercase.str.contains(r'\\bywbta\\b', literal=False)).then(pl.lit('YWBTA'))\n",
    "            .when(body_lowercase.str.contains(r'\\bywnbta\\b', literal=False)).then(pl.lit('YWNBTA'))\n",
    "            .when(body_lowercase.str.contains(r'\\byta\\b', literal=False)).then(pl.lit('YTA'))\n",
    "            .when(body_lowercase.str.contains(r'\\bnta\\b', literal=False)).then(pl.lit('NTA'))\n",
    "            .when(body_lowercase.str.contains(r'\\besh\\b', literal=False)).then(pl.lit('ESH'))\n",
    "            .when(body_lowercase.str.contains(r'\\bnah\\b', literal=False)).then(pl.lit('NAH'))\n",
    "            .otherwise(None)\n",
    "        )\n",
    "    )\n",
    "    .filter(pl.col('extracted_vote').is_not_null())\n",
    "    .select(['link_id', 'score', 'extracted_vote', 'body']) # TODO: remove body\n",
    ")\n",
    "\n",
    "if SHOULD_MAP_OTHER_FLAIRS:\n",
    "    comment_votes_lf = comment_votes_lf.with_columns(\n",
    "        pl.when(pl.col('extracted_vote').is_in(YTA_LIKE)).then(pl.lit('YTA'))\n",
    "        .when(pl.col('extracted_vote').is_in(NTA_LIKE)).then(pl.lit('NTA'))\n",
    "        .alias('extracted_vote')\n",
    "    )\n",
    "\n",
    "if SHOULD_PRINT_HEAD:\n",
    "    _ = display(comment_votes_lf.sort('score').collect(engine='streaming').head(N_HEAD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deec619",
   "metadata": {},
   "source": [
    "# Calculate (weighted) majority vote based on extracted comment votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6abb4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_submission_extracted_majority_votes_lf = (\n",
    "    comment_votes_lf\n",
    "    .group_by('link_id')\n",
    "    .agg(\n",
    "        n_yta=(pl.col('extracted_vote') == 'YTA').sum(),\n",
    "        n_nta=(pl.col('extracted_vote') == 'NTA').sum(),\n",
    "        weighted_yta=pl.when(pl.col('extracted_vote') == 'YTA').then(pl.col('score')).otherwise(0).sum(),\n",
    "        weighted_nta=pl.when(pl.col('extracted_vote') == 'NTA').then(pl.col('score')).otherwise(0).sum(),\n",
    "    )\n",
    "    .with_columns(\n",
    "        delta=pl.col('n_yta') - pl.col('n_nta'),\n",
    "        weighted_delta=pl.col('weighted_yta') - pl.col('weighted_nta'),\n",
    "        n_comments=pl.col('n_yta') + pl.col('n_nta')\n",
    "    )\n",
    "    .with_columns(\n",
    "        extracted_majority_vote=(\n",
    "            pl.when(pl.col('delta') > 0).then(pl.lit('YTA'))\n",
    "             .when(pl.col('delta') < 0).then(pl.lit('NTA'))\n",
    "             .otherwise(pl.lit('UNDECIDED'))\n",
    "        ),\n",
    "        extracted_weighted_majority_vote=(\n",
    "            pl.when(pl.col('weighted_delta') > 0).then(pl.lit('YTA'))\n",
    "             .when(pl.col('weighted_delta') < 0).then(pl.lit('NTA'))\n",
    "             .otherwise(pl.lit('UNDECIDED'))\n",
    "        ),\n",
    "        polarity=(\n",
    "            pl.when(pl.col('n_comments') > 0)\n",
    "            .then(\n",
    "                (pl.col('n_yta') - pl.col('n_nta'))\n",
    "                / pl.col('n_comments')\n",
    "            )\n",
    "            .otherwise(None) # TODO: filter out all nulls?\n",
    "        ),\n",
    "    )\n",
    "    .select(\n",
    "        'link_id',\n",
    "        'n_yta',\n",
    "        'n_nta',\n",
    "        'n_comments',\n",
    "        'extracted_majority_vote',\n",
    "        'extracted_weighted_majority_vote',\n",
    "        'polarity',\n",
    "    )\n",
    ")\n",
    "\n",
    "if SHOULD_PRINT_HEAD:\n",
    "    _ = display(per_submission_extracted_majority_votes_lf.collect(engine='streaming').head(N_HEAD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = pl.col('score')\n",
    "R = pl.col('upvote_ratio')\n",
    "denominator = 2 * R - 1\n",
    "n_downvotes = S * (1 - R) / denominator\n",
    "\n",
    "joined_lf = (\n",
    "    submission_features_lf\n",
    "    .join(\n",
    "        per_submission_extracted_majority_votes_lf,\n",
    "        left_on='name',\n",
    "        right_on='link_id',\n",
    "        how='inner',\n",
    "    )\n",
    "    .with_columns(\n",
    "        n_downvotes=(\n",
    "            pl.when(denominator != 0)\n",
    "            .then(n_downvotes.round(0).cast(pl.UInt32))\n",
    "            .otherwise(None)\n",
    "        ),\n",
    "    )\n",
    "    .with_columns(\n",
    "        n_upvotes=(\n",
    "            pl.when(denominator != 0)\n",
    "            .then((S + n_downvotes).round(0).cast(pl.UInt32))\n",
    "            .otherwise(None)\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "SUBMISSION_PATTERN_DATA_PARQUET = settings.DATA_DIR / 'submission_pattern_data.parquet'\n",
    "if not SUBMISSION_PATTERN_DATA_PARQUET.exists():\n",
    "    joined_lf.sink_parquet(SUBMISSION_PATTERN_DATA_PARQUET, engine='streaming')\n",
    "joined_lf = pl.scan_parquet(SUBMISSION_PATTERN_DATA_PARQUET)\n",
    "\n",
    "_ = display(joined_lf.collect(engine='streaming'))\n",
    "\n",
    "# if SHOULD_PRINT_HEAD:\n",
    "#     _ = display(joined_lf.collect(engine='streaming').head(N_HEAD))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ti3160tu-nlp-group-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
