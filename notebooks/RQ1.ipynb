{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2118b82e",
   "metadata": {},
   "source": [
    "## NLP Project - Preprocessing and RoBerta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11704680",
   "metadata": {},
   "source": [
    "Loading Reddit Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51857bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json \n",
    "\n",
    "import matplotlib as plt\n",
    "import seaborn as sns \n",
    "\n",
    "plt.style.use('ggplot')\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_json(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data \n",
    "\n",
    "def load_reddit_data(comments_directory, submissions_directory):\n",
    "    with open(comments_directory, 'r', encoding='utf-8') as file:\n",
    "        comment_id_pairs = []\n",
    "        for i, line in enumerate(file, 1):\n",
    "            try:\n",
    "                if i >= 10000000:\n",
    "                    break\n",
    "                data = json.loads(line)\n",
    "                body = data.get('body', '').strip() # Comment text\n",
    "                link_id = data.get('link_id', '').strip() # Link id\n",
    "                id = data.get('name', '').strip() # Specific id\n",
    "                comment_id_pairs.append((body, link_id))\n",
    "            except json.JSONDecodeError:\n",
    "                continue  # This is done to avoid missing comments or bad lines\n",
    "        comment_id_pairs = tuple(comment_id_pairs)\n",
    "        comments_dict = {id_: text for text, id_ in comment_id_pairs}\n",
    "        comments_dict = {id_: text for id_, text in comments_dict.items() if text not in (\"[deleted]\", \"[removed]\")} # To remove deleted or removed comments\n",
    "        #print(comments_dict)\n",
    "\n",
    "    with open(submissions_directory, 'r', encoding='utf-8') as file:\n",
    "        text_id_pairs = []\n",
    "        for i, line in enumerate(file, 1):\n",
    "            try:\n",
    "                if i >= 10000000:\n",
    "                    break\n",
    "                data = json.loads(line)\n",
    "                title = data.get('title', '').strip() # Submission title\n",
    "                body = data.get('selftext', '').strip() # Submission text\n",
    "                id = data.get('name', '').strip() # Specific id\n",
    "                \n",
    "                score = data.get('score')\n",
    "                upvote_ratio = data.get('upvote_ratio')\n",
    "\n",
    "                \n",
    "                #length of post\n",
    "                combined_text = (title + \" \" + body).strip()\n",
    "                post_len = len(combined_text)\n",
    "                text_id_pairs.append((title, body, id, score, post_len, upvote_ratio))\n",
    "            except json.JSONDecodeError:\n",
    "                continue # This is done to avoid missing comments or bad lines\n",
    "        submissions_dict = {\n",
    "            id: {\n",
    "                \"text\": (title + \" \" + body).strip(),\n",
    "                \"score\": score,\n",
    "                \"post_len\": post_len,\n",
    "                \"upvote_ratio\": upvote_ratio\n",
    "            }\n",
    "            for title, body, id, score, post_len, upvote_ratio in text_id_pairs\n",
    "            if (title + body).strip() not in (\"[deleted]\", \"[removed]\")\n",
    "        }\n",
    "    grouped = defaultdict(list)\n",
    "    res = []\n",
    "    for comment, id_ in comment_id_pairs:\n",
    "        if id_ in submissions_dict:\n",
    "            grouped[id_].append(comment)\n",
    "\n",
    "    banned_phrases = [\n",
    "        \"^^^^automod\",\n",
    "        \"welcome to /r/amitheasshole.\",\n",
    "        \"your post has been removed\",\n",
    "        \"#read this carefully\",\n",
    "        \"[removed]\",\n",
    "        \"[deleted]\"\n",
    "        ]\n",
    "\n",
    "    for id_, comments in grouped.items():\n",
    "        # This removes the copy of each submission because, each submission has an automated comment that starts with the string that is present in the code.\n",
    "        clean_comments = [c for c in comments  if len(c.strip()) > 0 and not any(phrase in c.lower() for phrase in banned_phrases)] \n",
    "        # The following statement is to avoid appending the list with submissions that have no comments at all\n",
    "        if not clean_comments:\n",
    "            continue\n",
    "        combined = (\n",
    "            submissions_dict[id_][\"text\"]\n",
    "            + \"[======>]\"\n",
    "            + \" \".join(clean_comments)\n",
    "            + f\" [==rq1==>] score={submissions_dict[id_]['score']}, length={submissions_dict[id_]['post_len']}, upvote_ratio={submissions_dict[id_]['upvote_ratio']}\"\n",
    "\n",
    "        )\n",
    "        res.append(combined)\n",
    "\n",
    "    res = [post for post in res if not any(p in post.lower() for p in banned_phrases)] # Copy of line clean_comments to ensure the data is filtered completely\n",
    "    #print(res[4])\n",
    "\n",
    "    with open(\"C:/Users/alexb/Desktop/Delft Minor/NLP Project/NLP Git/NLP_project/data/output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(res, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5814c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_dir = \"C:/Users/alexb/Desktop/Delft Minor/NLP Project/NLP Git/NLP_project/data/amitheasshole_comments.ndjson\"\n",
    "submissions_dir = \"C:/Users/alexb/Desktop/Delft Minor/NLP Project/NLP Git/NLP_project/data/amitheasshole_submissions.ndjson\"\n",
    "#reddit_data = load_reddit_data(comments_dir, submissions_dir) # Comment out after running it once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3aa46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the [ ['title+body'] =====> [comments] ==rq1==> [upvote_ratio] [post_len] ]\n",
    "with open(\"C:/Users/alexb/Desktop/Delft Minor/NLP Project/NLP Git/NLP_project/data/output.json\", \"r\", encoding='utf-8') as f:\n",
    "    rows = json.load(f)\n",
    "\n",
    "#loads a submission + all of its comments as a row called 'Raw' \n",
    "df = pd.DataFrame({\"raw\": rows})\n",
    "\n",
    "regex_seperate_post_comments = r\"\\s*\\[======>\\]\\s*\"\n",
    "regex_seperate_rq1_values = r\"\\s*\\[==rq1==>\\]\\s*\"\n",
    "#Creating Dictionary by splitting raw into post, comments columns\n",
    "df.insert(0, \"id\", range(1, len(df) + 1))\n",
    "\n",
    "#splitting into post + comment&data\n",
    "df[[\"post\", \"comments\"]] = df[\"raw\"].str.split(regex_seperate_post_comments, n=1, regex=True, expand=True)\n",
    "\n",
    "#seperating rq1 info from comments\n",
    "df[[\"comments\", \"rq1 data\"]] = df[\"comments\"].str.split(regex_seperate_rq1_values, n=1, regex=True, expand=True)\n",
    "df[\"rq1 data\"] = df[\"rq1 data\"].fillna(\"\")\n",
    "\n",
    "df[\"score\"] = pd.to_numeric(\n",
    "    df[\"rq1 data\"].str.extract(r\"score=\\s*(-?\\d+(?:\\.\\d+)?)\")[0],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "df[\"post_len\"] = (\n",
    "    pd.to_numeric(\n",
    "        df[\"rq1 data\"].str.extract(r\"length=\\s*(\\d+)\")[0],\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    .div(100)\n",
    "    .round()\n",
    "    .mul(100)\n",
    ")\n",
    "\n",
    "df[\"upvote_ratio\"] = pd.to_numeric(\n",
    "    df[\"rq1 data\"].str.extract(r\"upvote_ratio=([0-9]*\\.?[0-9]+)\")[0],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "df[\"comments\"] = df[\"comments\"].fillna(\"\")\n",
    "\n",
    "#Splitting all comments into a comment list\n",
    "df[\"comments_list\"] = df[\"comments\"].apply(lambda x: [c.strip() for c in re.split(r\"\\n\\s*\\n\", x.strip()) if c.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f134b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c229538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the verdict of the Comment \n",
    "asshole_spellings = r\"a[\\s\\-$]*s?[\\s\\-$]*s?[\\s\\-$]*h?[\\s\\-$]*o+[\\s\\-$]*(?:l+[\\s\\-$]*e*|e+[\\s\\-$]*l+)\"\n",
    "\n",
    "# --- YTA ---\n",
    "regex_spellings_YTA = re.compile(\n",
    "    rf\"\\b(?:YTA|you\\s*(?:'re|are|re)?\\s*(?:an?\\s*)?(?:the\\s*)?{asshole_spellings}|yes\\s+the\\s+{asshole_spellings})\\b\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# --- NTA ---\n",
    "regex_spellings_NTA = re.compile(\n",
    "    rf\"\\b(?:NTA|you\\s*(?:'re|are|re)?\\s*not\\s*(?:an?\\s*)?(?:the\\s*)?{asshole_spellings}|not\\s+the\\s+{asshole_spellings})\\b\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# --- ESH ---\n",
    "regex_spelling_esh = re.compile(\n",
    "    r\"\\b(?:ESH|everyone\\s+sucks\\s+here)\\b\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# --- NAH ---\n",
    "regex_spelling_nah = re.compile(\n",
    "    rf\"\\b(?:NAH|no\\s+(?:{asshole_spellings}s?|a[\\s\\-$]*-?holes?)\\s+here)\\b\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def extract_verdict(comment):\n",
    "    text = comment.lower()\n",
    "    if regex_spellings_YTA.search(text) or regex_spelling_esh.search(text):\n",
    "        return \"YTA\"\n",
    "    if regex_spellings_NTA.search(text) or regex_spelling_nah.search(text):\n",
    "        return \"NTA\"  \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def summarize_verdicts(comment_list):\n",
    "    counts = {\"YTA\":0, \"NTA\":0}\n",
    "    comment_list = comment_list or []\n",
    "    n_comments = len(comment_list)\n",
    "\n",
    "    for comment in (comment_list or []):\n",
    "        v = extract_verdict(comment)\n",
    "        if v in counts:\n",
    "            counts[v] += 1\n",
    "\n",
    "    n_verdicts = sum(counts.values())\n",
    "    if n_verdicts == 0:\n",
    "        return None, 0, 0, counts\n",
    "    majority = max(counts, key=counts.get)\n",
    "    polarization = abs(counts[\"YTA\"] - counts[\"NTA\"]) / n_verdicts\n",
    "    return majority, polarization, n_comments, n_verdicts, counts\n",
    "\n",
    "df[[\"majority\", \"polarization\", \"num_comments\", \"num_verdicts\", \"verdict_counts\"]] = (\n",
    "    df[\"comments_list\"].apply(lambda lst: pd.Series(summarize_verdicts(lst)))\n",
    ")\n",
    "sorted_list_num_comments = df.sort_values(by=\"num_comments\", ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_list_num_comments.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer \n",
    "from tqdm.notebook import tqdm # tracks loop progress through a bar\n",
    "\n",
    "sia = SentimentIntensityAnalyzer() #initalize and call it \n",
    "\n",
    "sia #object is created\n",
    "\n",
    "# run loop for scores\n",
    "results = {}\n",
    "for i, row in tqdm(sorted_list_num_comments.iterrows(), total=len(sorted_list_num_comments)):\n",
    "    text = row['post']\n",
    "    myid = row['id']\n",
    "    results[myid] = sia.polarity_scores(text)\n",
    "\n",
    "vader_results_posts = pd.DataFrame(results).T # T transposes the dictionary\n",
    "vader_results_posts = vader_results_posts.reset_index().rename(columns={'index': 'id'})\n",
    "vader_results_posts_soretd_num_comments = vader_results_posts.merge(sorted_list_num_comments, how='left')\n",
    "vader_results_posts_soretd_num_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7210d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- 1) Take a 20% sample (stratified-ish by random state) ---\n",
    "test_df = sorted_list_num_comments.sample(frac=0.20, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# --- 2) Prepare data from the sample only ---\n",
    "ids   = test_df[\"id\"].tolist()\n",
    "texts = test_df[\"post\"].astype(str).tolist()\n",
    "\n",
    "batch_size = 64\n",
    "max_length = 256\n",
    "\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "all_ids, all_probs = [], []\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size), desc=\"RoBERTa scoring (20% sample, batched)\"):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    enc = tokenizer(\n",
    "        batch_texts,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "\n",
    "    probs = softmax(logits.cpu().numpy(), axis=1)\n",
    "\n",
    "    neg_prob = probs[:, 0]   # negative\n",
    "    neu_prob = probs[:, 1]   # neutral\n",
    "    pos_prob = probs[:, 2]   # positive\n",
    "\n",
    "    compound = pos_prob - neg_prob \n",
    "\n",
    "    all_ids.extend(ids[i:i+batch_size])\n",
    "    all_probs.extend(hate_prob.tolist())\n",
    "\n",
    "# --- 4) Build results for the sample and merge (like VADER flow) ---\n",
    "roberta_results_posts_sorted_num_comments = pd.DataFrame({\"id\": all_ids, \"sent_compound\": all_probs})\n",
    "roberta_results_posts_sorted_num_comments = sorted_list_num_comments.merge(\n",
    "    test_df, how=\"left\", on=\"id\"\n",
    ")\n",
    "\n",
    "roberta_results_posts_sorted_num_comments.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_results_posts_sorted_num_comments[\"verdict_binary\"] = roberta_results_posts_sorted_num_comments[\"majority\"].map({\"YTA\": 1, \"NTA\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b012a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_results_posts_sorted_num_comments.loc[:,[\"score\",\"post_len\",\"upvote_ratio\",\"verdict_binary\"]] \n",
    "df_clean_roberta = roberta_results_posts_sorted_num_comments.dropna(subset=[\"verdict_binary\"]).copy()\n",
    "df_clean_roberta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3735c",
   "metadata": {},
   "source": [
    "# Data Explorationa and Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b1dc2a",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_results_posts_soretd_num_comments[\"verdict_binary\"] = vader_results_posts_soretd_num_comments[\"majority\"].map({\"YTA\": 1, \"NTA\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d3284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_results_posts_soretd_num_comments.loc[:,[\"score\",\"post_len\",\"upvote_ratio\",\"verdict_binary\"]] \n",
    "df_clean_vader = vader_results_posts_soretd_num_comments.dropna(subset=[\"verdict_binary\"]).copy()\n",
    "df_clean_vader.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634e4ef2",
   "metadata": {},
   "source": [
    "### Logistic Regression on post length vs YTA verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54575ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "features = [\"post_len\", \"score\", \"polarization\", \"num_comments\"]\n",
    "X = df_clean_vader[features]\n",
    "y = df_clean_vader[\"verdict_binary\"]\n",
    "log_reg_pipeline.fit(X, y)\n",
    "\n",
    "# Range of post lengths\n",
    "post_len_range = np.linspace(df_clean_vader[\"post_len\"].min(), df_clean_vader[\"post_len\"].max(), 500)\n",
    "\n",
    "# Build prediction DataFrame (keep others at mean)\n",
    "X_pred = pd.DataFrame({\n",
    "    \"post_len\": post_len_range,\n",
    "    \"score\": df_clean_vader[\"score\"].mean(),\n",
    "    \"polarization\": df_clean_vader[\"polarization\"].mean(),\n",
    "    \"num_comments\": df_clean_vader[\"num_comments\"].mean(),\n",
    "   \n",
    "})\n",
    "\n",
    "# Predict probability of YTA\n",
    "y_pred_prob = log_reg_pipeline.predict_proba(X_pred)[:, 1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(post_len_range, y_pred_prob, color=\"tomato\")\n",
    "plt.xlabel(\"Post Length\")\n",
    "plt.ylabel(\"Predicted Probability (YTA)\")\n",
    "plt.title(\"Predicted Probability of YTA vs Post Length\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": features,\n",
    "    \"Coefficient\": log_reg_pipeline.named_steps[\"model\"].coef_[0]\n",
    "}).sort_values(\"Coefficient\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coef_df, palette=\"coolwarm\")\n",
    "plt.title(\"Feature Influence on YTA vs NTA (Logistic Regression)\")\n",
    "plt.axvline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "y_pred = log_reg_pipeline.predict(X)\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Reds\",\n",
    "            xticklabels=[\"Pred NTA\", \"Pred YTA\"],\n",
    "            yticklabels=[\"True NTA\", \"True YTA\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix: Logistic Regression (YTA vs NTA)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06cb7e4",
   "metadata": {},
   "source": [
    "## LR with Vader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e560f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# ---- take 20% sample for fair comparison ----\n",
    "dfv = df_clean_vader.sample(frac=0.20, random_state=42).reset_index(drop=True)\n",
    "\n",
    "features = [\"post_len\",\"compound\" ,\"score\", \"polarization\", \"num_comments\"]\n",
    "# ensure numeric & drop missing rows for modeling\n",
    "dfv[features + [\"verdict_binary\"]] = dfv[features + [\"verdict_binary\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "dfv = dfv.dropna(subset=features + [\"verdict_binary\"])\n",
    "\n",
    "X = dfv[features]\n",
    "y = dfv[\"verdict_binary\"]\n",
    "\n",
    "# pipeline\n",
    "log_reg_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "log_reg_pipeline.fit(X, y)\n",
    "\n",
    "# ---- partial dependence: vary post_len, hold others at mean ----\n",
    "post_len_range = np.linspace(dfv[\"post_len\"].min(), dfv[\"post_len\"].max(), 500)\n",
    "means = dfv[features].mean(numeric_only=True)\n",
    "\n",
    "X_pred = pd.DataFrame({\n",
    "    \"post_len\": post_len_range,\n",
    "    \"score\": np.full_like(post_len_range, means[\"score\"], dtype=float),\n",
    "    \"compound\": np.full_like(post_len_range, means[\"compound\"],dtype=float),\n",
    "    \"polarization\": np.full_like(post_len_range, means[\"polarization\"], dtype=float),\n",
    "    \"num_comments\": np.full_like(post_len_range, means[\"num_comments\"], dtype=float),\n",
    "})[features]\n",
    "\n",
    "# Predict probability of YTA\n",
    "y_pred_prob = log_reg_pipeline.predict_proba(X_pred)[:, 1]\n",
    "\n",
    "# Plot P(YTA) vs post_len\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(post_len_range, y_pred_prob, color=\"tomato\")\n",
    "plt.xlabel(\"Post Length\"); plt.ylabel(\"Predicted Probability (YTA)\")\n",
    "plt.title(\"Predicted Probability of YTA vs Post Length (VADER)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "# Coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": features,\n",
    "    \"Coefficient\": log_reg_pipeline.named_steps[\"model\"].coef_[0]\n",
    "}).sort_values(\"Coefficient\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coef_df, palette=\"coolwarm\")\n",
    "plt.title(\"Feature Influence on YTA vs NTA (VADER)\")\n",
    "plt.axvline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.show()\n",
    "\n",
    "# Metrics on the 20% sample\n",
    "y_pred = log_reg_pipeline.predict(X)\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion matri Vader:\\n\", cm)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Reds\",\n",
    "            xticklabels=[\"Pred NTA\", \"Pred YTA\"],\n",
    "            yticklabels=[\"True NTA\", \"True YTA\"])\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix: Logistic Regression Vader\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60a8ba",
   "metadata": {},
   "source": [
    "### LR with Roberta\n",
    "- using compound and upvote to try improve regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# --- features & data ---\n",
    "features = [\"post_len\", \"score\", \"upvote_ratio\", \"polarization\", \"num_comments\", \"hate_prob\"]\n",
    "\n",
    "dfm = df_clean_roberta.copy()\n",
    "dfm[features] = dfm[features].apply(pd.to_numeric, errors=\"coerce\")\n",
    "dfm = dfm.dropna(subset=features + [\"verdict_binary\"]).reset_index(drop=True)\n",
    "\n",
    "X = dfm[features]\n",
    "y = dfm[\"verdict_binary\"]\n",
    "\n",
    "# --- pipeline ---\n",
    "log_reg_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "log_reg_pipeline.fit(X, y)\n",
    "\n",
    "# --- partial dependence: vary post_len, hold others at mean ---\n",
    "post_len_range = np.linspace(dfm[\"post_len\"].min(), dfm[\"post_len\"].max(), 500)\n",
    "means = dfm[features].mean(numeric_only=True)\n",
    "\n",
    "X_pred = pd.DataFrame({\n",
    "    \"post_len\": post_len_range,\n",
    "    \"score\": np.full_like(post_len_range, means[\"score\"], dtype=float),\n",
    "    \"upvote_ratio\": np.full_like(post_len_range, means[\"upvote_ratio\"], dtype=float),\n",
    "    \"polarization\": np.full_like(post_len_range, means[\"polarization\"], dtype=float),\n",
    "    \"num_comments\": np.full_like(post_len_range, means[\"num_comments\"], dtype=float),\n",
    "    \"hate_prob\": np.full_like(post_len_range, means[\"hate_prob\"], dtype=float),\n",
    "})[features]  # enforce exact column order\n",
    "\n",
    "# --- plot P(YTA) vs post_len ---\n",
    "y_pred_prob = log_reg_pipeline.predict_proba(X_pred)[:, 1]\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(post_len_range, y_pred_prob, color=\"tomato\")\n",
    "plt.xlabel(\"Post Length\")\n",
    "plt.ylabel(\"Predicted Probability (YTA)\")\n",
    "plt.title(\"Predicted Probability of YTA vs Post Length (RoBerta)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "# --- coefficients ---\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": features,\n",
    "    \"Coefficient\": log_reg_pipeline.named_steps[\"model\"].coef_[0]\n",
    "}).sort_values(\"Coefficient\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coef_df, palette=\"coolwarm\")\n",
    "plt.title(\"Feature Influence on YTA vs NTA (RoBerta)\")\n",
    "plt.axvline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.show()\n",
    "\n",
    "# --- in-sample metrics ---\n",
    "y_pred = log_reg_pipeline.predict(X)\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion matrix:\\n\", cm)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Reds\",\n",
    "            xticklabels=[\"Pred NTA\", \"Pred YTA\"],\n",
    "            yticklabels=[\"True NTA\", \"True YTA\"])\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix: Logistic Regression (RoBerta)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": features,\n",
    "    \"Coefficient\": log_reg_pipeline.named_steps[\"model\"].coef_[0]\n",
    "}).sort_values(\"Coefficient\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coef_df, palette=\"coolwarm\")\n",
    "plt.title(\"Feature Influence on YTA vs NTA (Logistic Regression)\")\n",
    "plt.axvline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee75a08",
   "metadata": {},
   "source": [
    "## Plot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6d57f",
   "metadata": {},
   "source": [
    "Post Length vs Upvote Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbcd13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "sns.kdeplot(data=dfv, x=\"polarization\", hue=\"verdict_binary\", fill=True, common_norm=False)\n",
    "plt.title(\"Polarity (Comment Sentiment) by Verdict\")\n",
    "plt.xlabel(\"Polarization Score\")\n",
    "plt.xticks()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc038ce2",
   "metadata": {},
   "source": [
    "Post Length vs Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd14b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib_inline\n",
    "import matplotlib.pyplot as plt\n",
    "sns.scatterplot(x=\"post_len\", y=\"score\", data=df, alpha=0.3, color=\"tomato\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Post Length\")\n",
    "plt.title(\"Post Length vs Score (log scale)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a66234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(dfv[\"polarization\"], kde=True, bins=40, color=\"purple\")\n",
    "plt.title(\"Distribution of Comment Polarity (Polarization)\")\n",
    "plt.xlabel(\"Polarization Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa16f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"post_len\", y=\"verdict_binary\", data=vader_results_posts_soretd_num_comments, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL A: with num_comments 2\n",
    "features_a = [\"post_len\", \"score\", \"upvote_ratio\", \"polarization\", \"num_comments\", \"hate_prob\"]\n",
    "\n",
    "# MODEL B: without num_comments (content only)\n",
    "features_b = [\"post_len\", \"score\", \"upvote_ratio\", \"polarization\", \"hate_prob\"]\n",
    "\n",
    "def train_and_plot(features, title_suffix):\n",
    "    X = dfm[features]\n",
    "    y = dfm[\"verdict_binary\"]\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    coef_df = pd.DataFrame({\n",
    "        \"Feature\": features,\n",
    "        \"Coefficient\": pipe.named_steps[\"model\"].coef_[0]\n",
    "    }).sort_values(\"Coefficient\", ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coef_df, palette=\"coolwarm\")\n",
    "    plt.title(f\"Logistic Regression Coefficients {title_suffix}\")\n",
    "    plt.axvline(0, color='black', linestyle='--')\n",
    "    plt.show()\n",
    "\n",
    "train_and_plot(features_a, \"(Including num_comments)\")\n",
    "train_and_plot(features_b, \"(No num_comments / content only)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd3c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"id\"\n",
    "\n",
    "cols_v = [\"id\",\"post_len\",\"score\",\"upvote_ratio\",\"polarization\",\"num_comments\",\n",
    "          \"compound\",\"verdict_binary\"]\n",
    "cols_m = [\"id\",\"hate_prob\"]\n",
    "\n",
    "dfc = (dfv[cols_v]\n",
    "       .merge(dfm[cols_m], on=key, how=\"inner\")\n",
    "       .copy())\n",
    "\n",
    "\n",
    "features_a = [\"post_len\",\"score\",\"upvote_ratio\",\"polarization\",\"num_comments\",\"compound\",\"hate_prob\"]\n",
    "features_b = [\"post_len\",\"score\",\"upvote_ratio\",\"polarization\",\"compound\",\"hate_prob\"]\n",
    "\n",
    "dfc[features_a + [\"verdict_binary\"]] = dfc[features_a + [\"verdict_binary\"]].apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    ")\n",
    "dfc = dfc.dropna(subset=features_a + [\"verdict_binary\"])\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_and_plot(df, features, title_suffix):\n",
    "    X = df[features]\n",
    "    y = df[\"verdict_binary\"]\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(max_iter=1000))\n",
    "    ]).fit(X, y)\n",
    "\n",
    "    coef_df = (pd.DataFrame({\n",
    "        \"Feature\": features,\n",
    "        \"Coefficient\": pipe.named_steps[\"model\"].coef_[0]\n",
    "    }).sort_values(\"Coefficient\", ascending=False))\n",
    "\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coef_df, palette=\"coolwarm\")\n",
    "    plt.title(f\"Logistic Regression Coefficients {title_suffix}\")\n",
    "    plt.axvline(0, color='black', linestyle='--')\n",
    "    plt.show()\n",
    "\n",
    "train_and_plot(dfc, features_a, \"(Including num_comments)\")\n",
    "train_and_plot(dfc, features_b, \"(Content-only: No comments)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125aa440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Feature label mapping (nice names for plotting) ----\n",
    "nice_names = {\n",
    "    \"post_len\": \"Post Length (chars)\",\n",
    "    \"score\": \"Score (Upvotes)\",\n",
    "    \"upvote_ratio\": \"Upvote Ratio\",\n",
    "    \"polarization\": \"Comment Polarity\",\n",
    "    \"compound\": \"Sentiment (Compound)\",\n",
    "    \"num_comments\": \"Number of Comments\",\n",
    "    \"hate_prob\": \"Hate Speech Probability\"\n",
    "}\n",
    "\n",
    "def train_and_plot(df, features, title_suffix):\n",
    "    X = df[features]\n",
    "    y = df[\"verdict_binary\"]\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(max_iter=1000))\n",
    "    ]).fit(X, y)\n",
    "\n",
    "    # Map features to nicer names here\n",
    "    coef_df = pd.DataFrame({\n",
    "        \"Feature\": [nice_names.get(f, f) for f in features],\n",
    "        \"Coefficient\": pipe.named_steps[\"model\"].coef_[0]\n",
    "    }).sort_values(\"Coefficient\", ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coef_df, palette=\"coolwarm\")\n",
    "    plt.title(f\"Logistic Regression Coefficients {title_suffix}\")\n",
    "    plt.axvline(0, color='black', linestyle='--')\n",
    "\n",
    "    plt.xlabel(\"Coefficient\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995eab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_plot(dfc, features_a, \"(Including num_comments)\")\n",
    "train_and_plot(dfc, features_b, \"(Content-only: No comments)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a850545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
